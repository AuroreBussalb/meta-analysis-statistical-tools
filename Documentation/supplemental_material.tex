% adding the line below for Multifile document support with LatexTools Sublime package 
%!TEX root = manuscript.tex
\documentclass[12pt,a4paper,english]{article}


\usepackage[utf8]{inputenc}
\usepackage[english]{babel}

% Quotes 
\usepackage[square]{natbib}
\bibliographystyle{abbrvnat}

% For hyperlinks in the pdf 
\usepackage{hyperref}

% Glossaries
\usepackage[acronym]{glossaries}

% Font Helvetica
\renewcommand{\familydefault}{\sfdefault}
\usepackage[T1]{fontenc}

% Margins
\usepackage[hmarginratio=1:1,top=32mm,columnsep=20pt]{geometry}

% For pictures in the pdf
\usepackage{graphicx}

% For tables
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{threeparttable}

% For ref with figure, table or equation before the number
\usepackage{cleveref}

% landscape page
\usepackage{lscape}



% This is for me to comment

% Not using the pdfcomment package but it is an interesting one  
%\usepackage[author={Louis Mayaud}]{pdfcomment}

% Select what to do with todonotes: 
% \usepackage[disable]{todonotes} % notes not showed
\usepackage[draft]{todonotes}   % notes showed

% Select what to do with command \comment:  
% \newcommand{\comment}[1]{}  %comment not showed
\newcommand{\comment}[1]
{\par {\bfseries \color{blue} #1 \par}} %comment showed


\input{glossaries}

\begin{document}



\title{Supplemental material}
\date{}
\maketitle

\section{Materials and methods}

\subsection{Perform a meta analysis}

To conduct meta-analysis, different software exist: for instance \citet{Cortese2016} used RevMan 5.3 \citep{RevMan} which computes the \gls{es} and its 
variance of each included study by applying the formula presented in \citet{Morris2008}. However, in order to compute the variance of the \gls{es}, 
the pooled within-group Pearson correlation $\rho$ (i.e the pre-post correlation) was required 
\citep{James2013}. In our case, this correlation was not known and the raw data were not available so we took an
 approximation: \citet{Balk2012} found that a value of 0.5 yields values closer to those computed with the right value of the correlation. 

In this replication of the work of \citeauthor{Cortese2016}, the same formulas are used \citep{Borenstein2009} but instead of using RevMan, 
a Python code was developed in order to perform the meta-analysis. To increase replicability and transparency and promote open science, we 
provide the full raw data used for this research as well as the Python code on a GitHub repository [put ref]; it is tested
with \citet{Cortese2016} raw data to show that same results were found and could be used for replication and expansion of this work. The toolbox
could also be used to run any similar meta-analysis. 

To perform the meta-analysis several steps must be followed. First the choice of the model: this analysis is based on either one of the following 
statistical models \citep{Borenstein2009}:
\begin{itemize}
    \item \emph{the fixed-effect model}: the true \gls{es} (i.e the \gls{es} that would be observed with an infinitely 
		large sample size) is the same for all the studies in the analysis. The differences between the actually observed \gls{es}s 
		are due to sampling errors;
    \item \emph{the random-effects model}: the true \gls{es} could vary from study to study. The differences between the observed
		\glspl{es} are due to sampling errors but also to the various designs of the studies (for instance the number of participants or the implementation).
\end{itemize}

In the present case, although the studies included into the meta-analysis meet the same criteria, they remain different from each other 
on various points, so the random effects model is more appropriate than the fixed-effect model.  

\subsection{Compute the effect size of each study}

First, the scores presented in the articles were extracted and the \gls{es} of each study as defined in \citet{Morris2008} 
was computed 

\begin{equation}
\label{eq:metareview_effect_size}
\text{ES} = c_p \left[ \frac{(M_{\text{post},T} - M_{\text{pre},T}) - (M_{\text{post},C} - M_{\text{pre},C}) }{\sigma_{\text{pre}}} \right ].
\end{equation} 
An \gls{es} is exactly equivalent to a z-score of a standard normal distribution, it is computed as mean pre- to post-treatment 
score change in the \gls{nfb} group ($M_{\text{pre},T}$, $M_{\text{post},T}$) minus the mean pre- to post- treatment score change 
in the control group ($M_{\text{pre},C}$, $M_{\text{post},C}$), divided by the pooled pre-test standard deviation ($\sigma_{\text{pre}}$) 

\begin{equation}
\label{eq:stats_metareview_std_pre}
\sigma_{\text{pre}} = \sqrt{\frac{(n_T - 1)\sigma_{\text{pre},T}^2 + (n_C - 1)\sigma_{\text{pre},C}^2} {n_T + n_C - 2}},
\end{equation}

where $\sigma_{t,G}$ indicates the standard deviation for group $G$ at time $t$ and $n_G$ defines the sample size of each group; 
$c_p$ is a bias adjustment typically used for small sample sizes

\begin{equation}
\label{eq:metareview_correction_factor}
c_p =  1 - \frac{3} {4(n_T + n_C - 2) - 1}. 
\end{equation} 

\subsection{Compute the variance of each effect size}

Then, the variance of each \gls{es} was computed \citep{Morris2008}
\begin{equation}
\label{eq:metareview_variance_ES}
\sigma^2(\text{ES}) = c_p^2 \left (\frac{n_T + n_C - 2} {n_T + n_C - 4} \right ) \left  [ \frac{2(1-\rho)(n_T + n_C)} {n_Tn_C} + \text{ES}^2 \right ] - \text{ES}^2.
\end{equation} 

To compute the variance of the \gls{es}, the pooled within-group Pearson correlation $\rho$ (i.e the pre-post correlation) was required 
\citep{James2013}:

\begin{equation}
\label{eq:metareview_within_group_pearson_correlation}
\rho =  \frac{ \sum_{i=1}^{n} (\text{pre}_i - \mu_{\text{pre}})(\text{post}_i - \mu_{\text{post}}) } { \sqrt{ \sum_{i=1}^{n} (\text{pre}_i - \mu_{\text{pre}})^2} \sqrt{\sum_{i=1}^{n} (\text{post}_i - \mu_{\text{post}})^2} }, 
\end{equation}
where $n$ is the number of patients included in a study, $pre_i$, $post_i$ are score values for patient $i$ at pre- and post-test 
respectively, and $\mu_{pre}$, $\mu_{post}$ the mean scores over all patients. It is a measure of linear correlation between two variables. 
A value of 1 means that there is a positive correlation whereas a value of -1 means a negative correlation. When $\rho=0$, there is no
linear correlation. In our case, this correlation was not known and the raw data were not available so we took an
approximation: \citet{Balk2012} found that a value of 0.5 yields values close to those computed with the right value of the correlation. 

Once variances were obtained with \cref{eq:metareview_variance_ES}, we could compute the standard error and the 95\% confidence interval of each \gls{es}. 

\subsection{Compute the weight of each study}

To compute the \gls{se} a weight must be assigned to each study. To obtain them several steps must be followed. At first, the fixed-effects model 
weight $w_{fixed}$ of each study $k$ was computed as defined in \citet{Borenstein2009}: 

\begin{equation}
\label{eq:metareview_weight_fixed_study}
w_{\text{fixed}_k} = \frac{1}{\sigma^2(\text{ES}_k)}.
\end{equation} 

Nevertheless, we chose to use the random effects model, so the weights associated to this model are different. To compute them, the between-studies 
variance $\tau^2$ is required. It was calculated in three steps described in \cref{eq:metareview_Q}, \cref{eq:metareview_C} and \cref{eq:metareview_Tau} 
\citep{Borenstein2009}:

\begin{equation}
\label{eq:metareview_Q}
Q = \sum_{k=1}^{K} (w_{\text{fixed}_k} \text{ES}_k^2),
\end{equation}

\begin{equation}
\label{eq:metareview_C}
C = \sum_{k=1}^{K} (w_{\text{fixed}_k} - \frac{ \sum_{k=1}^{K} (w_{\text{fixed}_k})^2 } { \sum_{k=1}^{K} (w_{\text{fixed}_k}) },
\end{equation}
with $K$ the total number of included studies.

\begin{equation}
\label{eq:metareview_Tau}
\tau^2 = \frac{Q - \text{df}}{C},
\end{equation}
with $\text{df} = K - 1$ the degrees of freedom.

The random-effects model takes into account the differences between the studies, so the weights are equal to the inverse of the addition between the 
within-study variance (the variance of the \gls{es}) and the between-studies variance

\begin{equation}
\label{eq:metareview_weight_study}
w_k = \frac{1}{\sigma^2(\text{ES}_k) + \tau^2}.
\end{equation} 

\subsection{Compute the summary effect}

Eventually, the weighted average of the $K$ \gls{es} was computed to obtain the \gls{se} as described in 
\cref{eq:metareview_summary_effect} \citep{Borenstein2009}:

\begin{equation}
\label{eq:metareview_summary_effect}
\text{SE} = \frac{\sum_{k=1}^{K} w_k \text{ES}_k} {\sum_{k=1}^{K} w_k}.
\end{equation} 

Once the \gls{se}  is obtained, we can compute its variance, its standard error, its 95\% confidence interval, its p-value, 
and $I^2$ estimating effects size's between studies heterogeneity. 

\subsection{Scales used for the meta-analysis}

All scales used for the meta-analysis are summarized here in order to facilitate the replication of this work.

\begin{table}[h!]
  \centering
  \caption{Clinical scales used to update \citet{Cortese2016} with our choices and the two new articles.}
\input{tables/table_meta_review_clinical_scales}
  \label{Table:Table_mr_clinical_scales_update_cortese}
\end{table}


\subsection{Associate independent factors to effect sizes}

Three different methods were used to perform the \gls{saob}:
\begin{itemize}
	\item weighted multiple linear regression (\gls{wls}) \citep{Montgomery2012}; 
	\item sparsity-regularized linear regression with \gls{lasso} \citep{Tibshirani1996};
	\item decision tree \citep{Quinlan1986}.
\end{itemize}

However, before interpreting the results of the \gls{wls}, the assumptions of this model had to be checked (distribution of the residuals was normal,
the moment matrix was full rank, the fit was significant and the independent variables were uncorrelated). 

To perform the \gls{lasso}, the tuning parameter $\lambda$ has to be determined. To do so, we used the leave-one-out cross validation method. 
This method retains 1 observation as the validation data for testing the model and the 
remaining $n$ - 1 observations are used as training data. The cross-validation process is then repeated $n$ times with each of the observation 
used exactly once as the testing data. For each fold, the \gls{mse} on the test set was computed and eventually, the $n$ results can 
be averaged to produce a single observation that enables to find the optimal $\lambda$: it corresponds to the abscissa of the minimum
value of the \gls{mse} on the mean fold computed for a large range of $\lambda$ \citep{James2013}. 

No weights are applied when running the \gls{lasso} and the decision tree because the frameworks don't easily account for this.


\clearpage

\section{Results}

\subsection{Perform a meta-analysis}

First, when using the \gls{es} found by \citet{Cortese2016} thanks to RevMan \citep{RevMan}, and then performed the following steps 
of meta-analysis with the Python code, we observe no major differences between these results and those obtained with RevMan \citep{RevMan} 
as listed in \cref{Table:meta_review_comparison_between_revman_python}. The minor discrepancies, especially observed at the p-values level,
are due to our choice to always use a pre-post correlation of 0.5 when computing the variance of each \gls{es}. Moreover, a sensitivity 
analysis was conducted to ensure the minor impact of the pre-post correlation value: when it varies between 0.2 and 0.8 the significance 
of the \gls{se} does not change. 

\begin{table}[h!]
  \centering
  \caption{Comparison between \citet{Cortese2016} results obtained with RevMan \citep{RevMan} and those obtained with the Python code. Summary 
	effects and their corresponding p-value in parenthesis are presented. With the Python program, a negative summary effect is in favor of \gls{nfb}.}
\input{tables/table_meta_review_comparison_revman_python}
  \label{Table:meta_review_comparison_between_revman_python}
\end{table}

Thanks to the previous step, we can conclude that the Python code yields results close to those returned by RevMan \citet{RevMan}, so we decide to
use this code to perform our meta-analysis.		

\subsection{Detect factors influencing the Neurofeedback}
		
To assess the variability of each factor, box plots of their standardized values were displayed in \cref{Figure:factors_analysis_boxplots}: treatment length, 
session length and number of sessions are more variable across studies than session pace, minimum and maximum age.  

\begin{figure}[h!]
	\center
  \includegraphics[scale=0.5]{figures/factors_analysis_boxplot_no_colors_no_two_columns}
  \caption{Boxplots of the standardized values of each continuous factor.}
  \label{Figure:factors_analysis_boxplots}
\end{figure}

\subsection{Assumptions for applying linear regression}

The first method used to detect the influencing factors was the \gls{wls}. The assumptions inherent to this method are checked: 
\begin{itemize}
	\item the moment matrix $\mathbf{{X}^{T}W^{T}WX}$ was invertible;
  \item no apparent correlation between the continuous independent variables was found; 
  \item the fit was significant as shown by the F-statistic (prob(F-statistic) = 2.81e-10); 
  \item the residuals were normally distributed as demonstrated by the skew (-0.15), kurtosis (2.81) and the Omnibus test (prob(Omnibus) = 0.87).
\end{itemize} 

These assumptions are also satisfied for the \gls{ols}.

\clearpage

\bibliography{bibliography}

\end{document}