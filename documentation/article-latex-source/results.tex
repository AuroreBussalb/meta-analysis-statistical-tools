% adding the line below for Multifile document support with LatexTools Sublime package 
%!TEX root = manuscript.tex


% Results

\section{Results}

\subsection{Selected studies}

Search terms entered in Pubmed returned 152 results during the last check on February 12, 2018, including 28 
articles used in previous meta-analyses on \gls{nfb}. After the selection process illustrated 
in Figure~\ref{Figure:systematic_review_workflow}, 31 studies were included in the \gls{saob} and 15 in the meta-analysis 
as summarized in Table~\ref{Table:table_factors_analysis_meta_analysis_list_studies}. The 31 studies selected for the \gls{saob} 
followed the \citeauthor{Cortese2016}'s criteria, with the exception of the requirement for a control group. 
Indeed, since within-\gls{es} were considered in this analysis, a control group was not required.

\subsection{Meta-analysis}

The Python module developed and used for this work was validated (details available in Supplemental Materials) 
and the code was made available online \citep{Bussalb2018}.

The replication and the update of \citeauthor{Cortese2016}'s study was conducted by applying the choices described 
in the Materials and Methods section and the results obtained are presented 
in Table~\ref{Table:meta_review_comparison_revman_and_python_with_choices}:

\begin{itemize}
    \item when computing the \gls{es} for \citet{Arnold2014} with the values after 40 sessions of \gls{nfb}, 
      smaller \gls{es} were found than \citet{Cortese2016}. This was unexpected as  
			the clinical efficacy might be supposed to increase with the number of \gls{nfb} sessions;  
    \item when relying on the teachers' ratings from the Conners-3 to compute the \gls{es} of \citet{Steiner2014}, 
		higher \gls{se} were found in attention but not for total and hyperactivity score. However, this different choice of 
		scale did not affect the statistical significance of the \glspl{se}.
\end{itemize}

The meta-analysis was then extended by adding two new articles \citep{Strehl2017, Baumeister2016} found 
by applying the same search criteria and finding more recent matches. \citet{Baumeister2016} provided results 
only for parents total outcome whereas \citet{Strehl2017} gave teachers and parents' assessments for all outcomes. 
Despite favorable results for \gls{nfb}, particularly on parents' assessments, adding these two new studies did not 
change neither the magnitude nor the significance of the \gls{se}, for any outcome whatever the raters,
as illustrated in Figure~\ref{Figure:meta_review_forest_plots_update_meta_analysis_our_choices_no_colors_2-columns_fitting_image}. 
 
As initially suggested by \citeauthor{Cortese2016}, the analysis was ran on two subgroups of studies: one gathering 
studies following the standard protocol defined by \citet{Arns2014} and a second including only participants not taking medications 
during the clinical trial. 

Regarding the `standard protocol' subgroup, \citet{Cortese2016} found all the outcomes significant except for the 
hyperactivity symptoms rated by teachers, which only showed a statistical trend (p-value = 0.11). Similar results 
were obtained when adding the most recent studies meeting this definition \citep{Strehl2017} (p-value = 0.11). 
The \gls{se} for the total outcome assessed by teachers remained significant with the addition of the two new
\glspl{rct} (p-value = 0.043), giving more power to this result since it is now based on four studies including 283
patients in total.

As for the no-drug subgroup, \glspl{se} were found significant for the inattention symptoms assessed by parents (p-value = 0.013). 
Besides, the differences in \citet{Arnold2014} values caused a loss of significance in hyperactivity outcome for parents 
(p-value = 0.066) compared to \citet{Cortese2016} (p-value = 0.016). The two new studies were not included in this 
subgroup because subjects were taking psychostimulants during the trial.

All the clinical scales used to compute the \gls{es} following our choices are summarized in the Supplemental Materials.

\subsection{Factors influencing Neurofeedback}

This analysis was performed on 31 trials assessing the efficacy of \gls{nfb} as presented 
in Table~\ref{Table:table_factors_analysis_meta_analysis_list_studies}. Among the 25 factors selected, six were 
removed because there were too many missing observations or because they were too homogeneous: beta up in frontal areas, 
the use of a transfer card, the type of threshold for the rewards (incremental or fixed), the EEG quality equal of 3
(meaning that the electrodes used were either \gls{agcl}/Gel or \gls{au}/Gel, a check of electrode contact quality was
performed, and the hardware used was CE marked), and the presence of a control group. 

All results are presented in Table~\ref{Table:table_factors_analysis_results_summary}. These results require a 
careful interpretation since each technique provided with slightly different results. These differences 
may depend on the different assumptions of the model and several other factors. In any case, we are inclined to 
trust those findings that are consistent across methods. 

The \gls{wls} technique identified eight significant factors for an adjusted R-squared of 0.74. 
When applying the \gls{ols}, the same factors were significant, except the presence of 
a transfer phase, the protocol theta down, and the artifact correction based on amplitude, with a lower adjusted R-squared 
(0.42). The \gls{lasso} regression selected 12 significant factors. With these methods, a negative coefficient means 
that the factor was in favor  of the efficacy of \gls{nfb}. The decision tree is presented in Figure~\ref{Figure:factors_analysis_decision_tree_results}. 
The best predictor is at the top of the tree: in our case it was 
the \gls{pblind}. Five other factors also split the subsets, however, the lower we get into the tree, the less samples are 
available, making the interpretation more and more doubtful.  

Several factors were common to the three methods used. In particular; the treatment length, the assessment 
by a blind rater, and an \gls{eeg} quality score equal to 2 (meaning that at least one of the three quality criteria had to be fulfilled).
The methods also agreed on the direction of the effect for these factors: 
a shorter treatment and recording the \gls{eeg} with a good-quality system seems preferable, whereas teachers' assessment appears less favorable
as compared to parents' assessment.

It is more doubtful the influence of the factors returned by only one or two methods. In particular: 
both \gls{wls} and \gls{lasso} found that relying on the amplitude of the signal to correct artifacts and including a transfer 
phase seems not to improve \gls{adhd} symptoms. Conversely, the \gls{irb} approval, a theta down protocol, and a higher number 
of sessions per week appears to positively influence the efficacy of the \gls{nfb} treatment. The decision tree and \gls{lasso} had in common the protocol 
\gls{smr}: it was associated with lower \gls{es}. Five factors were returned by only one of the methods: the minimal age of the 
children, being on drugs during \gls{nfb} treatment, randomizing the groups and the \glspl{scp} protocol.  

Five factors were never selected by the three methods: the correction for the ocular artifact, the children maximum age, the number 
of sessions, the protocol beta up in central areas and the presence of more than one active electrode. Thus, these factors definitely appear 
not to have an influence on \gls{nfb} efficacy.  

In the next section we discuss only the factors that were selected by at least two of the three methods. 

% words number = 1017
